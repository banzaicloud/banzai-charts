{{- $schema := first (splitList ":" .Values.app.logDirectory) }}
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: {{ template "spark-hs.fullname" . }}
  labels:
    app: {{ template "spark-hs.fullname" . }}
    chart: "{{ .Chart.Name }}-{{ .Chart.Version }}"
    release: "{{ .Release.Name }}"
    heritage: "{{ .Release.Service }}"
spec:
  replicas: {{ .Values.replicaCount }}
  template:
    metadata:
      labels:
        app: {{ template "spark-hs.fullname" . }}
    spec:
      initContainers:
      {{- if eq $schema "wasb" }}
      - name: {{ .Chart.Name }}-init-config
        image: alpine
        imagePullPolicy: {{ .Values.image.pullPolicy }}
        envFrom:
          - secretRef:
              name: {{ default (printf "%s" (include "spark-hs.fullname" .)) .Values.secretNameOverride }}
        command:
          - '/bin/sh'
          - '-c'
          - >
            echo -n spark.hadoop.fs.azure.account.key.$AZURE_STORAGE_ACCOUNT_NAME.blob.core.windows.net=$AZURE_STORAGE_ACCESS_KEY > /opt/spark/conf/spark-defaults.conf
        volumeMounts:
          - name: config-volume
            mountPath: /opt/spark/conf/
      {{- else if and (eq $schema "gs") .Values.secretName }}
      - name: {{ .Chart.Name }}-init-config
        image: jiapantw/jq-alpine:latest
        imagePullPolicy: {{ .Values.image.pullPolicy }}
        command:
          - '/bin/sh'
          - '-c'
          - >
            find /google-secret-path/ -type f -exec jq --slurp --raw-input '{key: input_filename|split("/")|last, value: .|rtrimstr("\n")}' {} \; | jq --slurp from_entries > /opt/spark/conf/google.json
        volumeMounts:
          - name: config-volume
            mountPath: /opt/spark/conf/
          - name: google-secrets
            mountPath: /google-secret-path/
            readOnly: true
      {{- end }}
      containers:
      - name: {{ .Chart.Name }}
        image: "{{ .Values.image.repository }}:{{ .Values.image.tag }}"
        imagePullPolicy: {{ .Values.image.pullPolicy }}
        env:
          - name: SPARK_NO_DAEMONIZE
            value: "false"
          - name: SPARK_HISTORY_OPTS
            value: >-
              -Dspark.history.fs.logDirectory={{ .Values.app.logDirectory }}
        {{- if eq $schema "gs" }}
          - name: GOOGLE_APPLICATION_CREDENTIALS
            value: /opt/spark/conf/google.json
        {{- else }}
        envFrom:
          - secretRef:
              name: {{ default (printf "%s" (include "spark-hs.fullname" .)) .Values.secretName }}
        {{- end }}
        volumeMounts:
        {{- if eq $schema "wasb" }}
          - name: config-volume
            mountPath: /opt/spark/conf/spark-defaults.conf
            subPath: spark-defaults.conf
        {{- else if eq $schema "gs" }}
          - name: config-volume
            mountPath: /opt/spark/conf/google.json
            subPath: google.json
        {{- end }}
        ports:
          - name: http
            containerPort: {{ .Values.service.internalPort }}
            protocol: TCP
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
        resources:
{{ toYaml .Values.resources | indent 12 }}
      volumes:
        - name: config-volume
          emptyDir: {}
      {{- if eq $schema "gs" }}
        - name: google-secrets
          secret:
            secretName: {{ default (printf "%s" (include "spark-hs.fullname" .)) .Values.secretName }}
      {{- end }}